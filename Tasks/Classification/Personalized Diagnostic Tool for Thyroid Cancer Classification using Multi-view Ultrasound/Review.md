# Personalized Diagnostic Tool for Thyroid Cancer Classification using Multi-view Ultrasound


#### Accepted by MICCAI 2022
#### Official code : None
###### Cite as : Huang, Han, et al. "Personalized Diagnostic Tool for Thyroid Cancer Classification Using Multi-view Ultrasound." Medical Image Computing and Computer Assisted Intervention–MICCAI 2022: 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part III. Cham: Springer Nature Switzerland, 2022.
------


### Abstract
> Over the past decades, the incidence of thyroid cancer has been increasing globally. Accurate and early diagnosis allows timely treatment and helps to avoid over-diagnosis. Clinically, a nodule is commonly evaluated from both transverse and longitudinal views using thyroid ultrasound. However, the appearance of the thyroid gland and lesions can vary dramatically across individuals. Identifying key diagnostic information from both views requires specialized expertise. Furthermore, finding an optimal way to integrate multi-view information also relies on the experience of clinicians and adds further difficulty to accurate diagnosis. To address these, we propose a personalized diagnostic tool that can customize its decision-making process for different patients. It consists of a multi-view classification module for feature extraction and a personalized weighting allocation network that generates optimal weighting for different views. It is also equipped with a self-supervised view-aware contrastive loss to further improve the model robustness towards different patient groups. Experimental results show that the proposed framework can better utilize multi-view information and outperform the competing methods.

> 지난 수십년간 갑상선 암의 발병률은 전세계적으로 증가로 조기 진단의 필요성이 대두됨. 갑상선의 해부학적 특징상 개인별 병변의 크기와 모양은 크게 다르므로 본 논문에서는 갑상선의 가로, 세로 방향의 multi-view 초음파 사진을 사용하여 결절 평가를 하고자 함. 특징 추출을 위한 multi-view classification으로 최적의 가중치 생성하는 네트워크 제안하고 모델 견고성을 향상 시키기 위해 self-supervised view-aware contrastive loss 적용하였음. 그 결과 ACC=83.29%, SEN=89.97%, SPE=70.31%, PRE=85.49% and F1-score=87.67% 의 성능을 보임
--------
### Introduction

#### Dataset
#### Training and Inference
#### Model Architectures

---------
### Result


--------
### Contribution




--------
### Conclusion
